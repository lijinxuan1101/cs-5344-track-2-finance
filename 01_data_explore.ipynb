{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf7d2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb9cb1",
   "metadata": {},
   "source": [
    "#### load datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "667e3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_test = pd.read_csv(\"./data/raw_data/loans_test.csv\")\n",
    "loans_train = pd.read_csv(\"./data/raw_data/loans_train.csv\")\n",
    "loans_valid = pd.read_csv(\"./data/raw_data/loans_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1469d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common columns: 143\n",
      "Common columns example: ['0_CurrentActualUPB', '0_CurrentInterestRate', '0_CurrentNonInterestBearingUPB', '0_EstimatedLTV', '0_InterestBearingUPB', '0_LoanAge', '0_MonthlyReportingPeriod', '0_RemainingMonthsToLegalMaturity', '10_CurrentActualUPB', '10_CurrentInterestRate'] ...\n",
      "\n",
      "Columns only in train: ['index', 'target']\n",
      "Columns only in valid: ['index', 'target']\n",
      "Columns only in test: ['Id']\n",
      "\n",
      "All uncommon columns: ['Id', 'index', 'target']\n"
     ]
    }
   ],
   "source": [
    "# check data columns\n",
    "# Correct dataset mapping\n",
    "cols_train = set(loans_train.columns)  # Training set\n",
    "cols_valid = set(loans_valid.columns)  # Validation set\n",
    "cols_test  = set(loans_test.columns)   # Test set\n",
    "\n",
    "common_cols = cols_train & cols_valid & cols_test\n",
    "only_train  = cols_train - common_cols\n",
    "only_valid  = cols_valid - common_cols\n",
    "only_test   = cols_test  - common_cols\n",
    "uncommon    = (cols_train | cols_valid | cols_test) - common_cols\n",
    "\n",
    "print(\"Number of common columns:\", len(common_cols))\n",
    "print(\"Common columns example:\", sorted(list(common_cols))[:10], \"...\")\n",
    "print(\"\\nColumns only in train:\", sorted(list(only_train)))\n",
    "print(\"Columns only in valid:\", sorted(list(only_valid)))\n",
    "print(\"Columns only in test:\", sorted(list(only_test)))\n",
    "print(\"\\nAll uncommon columns:\", sorted(list(uncommon)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e300e",
   "metadata": {},
   "source": [
    "### data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12ca9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting FirstPaymentDate...\n",
      "  ✓ FirstPaymentDate converted to datetime\n",
      "Converting MaturityDate...\n",
      "  ✓ MaturityDate converted to datetime\n",
      "\n",
      "Converting MonthlyReportingPeriod columns...\n",
      "Found 14 MonthlyReportingPeriod columns\n",
      "  ✓ 14 MonthlyReportingPeriod columns converted\n",
      "\n",
      "=== Verification ===\n",
      "Date column data types after conversion:\n",
      "  FirstPaymentDate: datetime64[ns]\n",
      "  MaturityDate: datetime64[ns]\n",
      "\n",
      "MonthlyReportingPeriod sample after conversion:\n",
      "  0_MonthlyReportingPeriod: [Timestamp('2024-02-01 00:00:00'), Timestamp('2024-02-01 00:00:00'), Timestamp('2024-02-01 00:00:00'), Timestamp('2024-02-01 00:00:00'), Timestamp('2024-02-01 00:00:00')]\n",
      "  1_MonthlyReportingPeriod: [Timestamp('2024-03-01 00:00:00'), Timestamp('2024-03-01 00:00:00'), Timestamp('2024-03-01 00:00:00'), Timestamp('2024-03-01 00:00:00'), Timestamp('2024-03-01 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime format\n",
    "\n",
    "# Convert FirstPaymentDate and MaturityDate\n",
    "for col in ['FirstPaymentDate', 'MaturityDate']:\n",
    "    if col in loans_train.columns:\n",
    "        print(f\"Converting {col}...\")\n",
    "        loans_train[col] = pd.to_datetime(loans_train[col])\n",
    "        loans_valid[col] = pd.to_datetime(loans_valid[col])\n",
    "        loans_test[col] = pd.to_datetime(loans_test[col])\n",
    "        print(f\"  ✓ {col} converted to datetime\")\n",
    "\n",
    "# Convert MonthlyReportingPeriod columns (YYYYMM format)\n",
    "print(\"\\nConverting MonthlyReportingPeriod columns...\")\n",
    "monthly_cols = [col for col in loans_train.columns if 'MonthlyReportingPeriod' in col]\n",
    "print(f\"Found {len(monthly_cols)} MonthlyReportingPeriod columns\")\n",
    "\n",
    "for col in monthly_cols:\n",
    "    # Convert YYYYMM format to datetime\n",
    "    loans_train[col] = pd.to_datetime(loans_train[col], format='%Y%m')\n",
    "    loans_valid[col] = pd.to_datetime(loans_valid[col], format='%Y%m')\n",
    "    loans_test[col] = pd.to_datetime(loans_test[col], format='%Y%m')\n",
    "\n",
    "print(f\"  ✓ {len(monthly_cols)} MonthlyReportingPeriod columns converted\")\n",
    "\n",
    "# Verify conversions\n",
    "print(\"\\n=== Verification ===\")\n",
    "print(\"Date column data types after conversion:\")\n",
    "for col in ['FirstPaymentDate', 'MaturityDate']:\n",
    "    if col in loans_train.columns:\n",
    "        print(f\"  {col}: {loans_train[col].dtype}\")\n",
    "\n",
    "print(f\"\\nMonthlyReportingPeriod sample after conversion:\")\n",
    "print(f\"  0_MonthlyReportingPeriod: {loans_train['0_MonthlyReportingPeriod'].head().tolist()}\")\n",
    "print(f\"  1_MonthlyReportingPeriod: {loans_train['1_MonthlyReportingPeriod'].head().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef505d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11f43370",
   "metadata": {},
   "source": [
    "### vacancy and distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "079325d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Vacancy Analysis ===\n",
      "\n",
      "--- Overall Missing Data Summary ---\n",
      "Total features: 145\n",
      "Features with missing data: 4\n",
      "Features with complete data: 141\n",
      "\n",
      "Top 20 features with most missing data:\n",
      "                          Missing_Count  Missing_Percentage\n",
      "ReliefRefinanceIndicator          30504          100.000000\n",
      "PreHARP_Flag                      30504          100.000000\n",
      "SuperConformingFlag               30176           98.924731\n",
      "MSA                                3422           11.218201\n",
      "index                                 0            0.000000\n",
      "FirstTimeHomebuyerFlag                0            0.000000\n",
      "target                                0            0.000000\n",
      "FirstPaymentDate                      0            0.000000\n",
      "CreditScore                           0            0.000000\n",
      "OccupancyStatus                       0            0.000000\n",
      "OriginalCLTV                          0            0.000000\n",
      "OriginalDTI                           0            0.000000\n",
      "OriginalUPB                           0            0.000000\n",
      "OriginalLTV                           0            0.000000\n",
      "MaturityDate                          0            0.000000\n",
      "MI_Pct                                0            0.000000\n",
      "NumberOfUnits                         0            0.000000\n",
      "PPM_Flag                              0            0.000000\n",
      "Channel                               0            0.000000\n",
      "OriginalInterestRate                  0            0.000000\n",
      "\n",
      "--- Missing Data by Feature Type ---\n",
      "Static features: 31\n",
      "Time series features: 112\n",
      "Static features missing data summary:\n",
      "  Features with missing data: 4\n",
      "  Average missing percentage: 10.00%\n",
      "Time series features missing data summary:\n",
      "  Features with missing data: 0\n",
      "  Average missing percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive analysis of data vacancy\n",
    "print(\"=== Data Vacancy Analysis ===\")\n",
    "print()\n",
    "\n",
    "# 1. Overall missing data summary\n",
    "print(\"--- Overall Missing Data Summary ---\")\n",
    "missing_summary = loans_train.isnull().sum().sort_values(ascending=False)\n",
    "missing_pct = (missing_summary / len(loans_train)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_summary,\n",
    "    'Missing_Percentage': missing_pct\n",
    "})\n",
    "\n",
    "print(f\"Total features: {len(loans_train.columns)}\")\n",
    "print(f\"Features with missing data: {(missing_summary > 0).sum()}\")\n",
    "print(f\"Features with complete data: {(missing_summary == 0).sum()}\")\n",
    "print()\n",
    "\n",
    "# Show top 20 features with most missing data\n",
    "print(\"Top 20 features with most missing data:\")\n",
    "print(missing_df.head(20).to_string())\n",
    "print()\n",
    "\n",
    "# 2. Missing data patterns by feature type\n",
    "print(\"--- Missing Data by Feature Type ---\")\n",
    "\n",
    "# Categorize features\n",
    "static_features = [col for col in loans_train.columns if not col.startswith(('0_', '1_', '2_', '3_', '4_', '5_', '6_', '7_', '8_', '9_', '10_', '11_', '12_', '13_')) and col not in ['index', 'target']]\n",
    "time_series_features = [col for col in loans_train.columns if col.startswith(('0_', '1_', '2_', '3_', '4_', '5_', '6_', '7_', '8_', '9_', '10_', '11_', '12_', '13_'))]\n",
    "\n",
    "print(f\"Static features: {len(static_features)}\")\n",
    "print(f\"Time series features: {len(time_series_features)}\")\n",
    "print()\n",
    "\n",
    "# Analyze missing data by feature type\n",
    "static_missing = loans_train[static_features].isnull().sum()\n",
    "time_series_missing = loans_train[time_series_features].isnull().sum()\n",
    "\n",
    "print(\"Static features missing data summary:\")\n",
    "print(f\"  Features with missing data: {(static_missing > 0).sum()}\")\n",
    "print(f\"  Average missing percentage: {static_missing.mean() / len(loans_train) * 100:.2f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Time series features missing data summary:\")\n",
    "print(f\"  Features with missing data: {(time_series_missing > 0).sum()}\")\n",
    "print(f\"  Average missing percentage: {time_series_missing.mean() / len(loans_train) * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7477f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 columns: ['ReliefRefinanceIndicator', 'PreHARP_Flag']\n",
      "New shapes - Train: (30504, 143), Valid: (5370, 143), Test: (13426, 142)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with 100% missing data directly\n",
    "columns_to_drop = ['ReliefRefinanceIndicator', 'PreHARP_Flag']\n",
    "\n",
    "# Drop columns directly from original datasets\n",
    "loans_train.drop(columns=columns_to_drop, inplace=True)\n",
    "loans_valid.drop(columns=columns_to_drop, inplace=True)\n",
    "loans_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(columns_to_drop)} columns: {columns_to_drop}\")\n",
    "print(f\"New shapes - Train: {loans_train.shape}, Valid: {loans_valid.shape}, Test: {loans_test.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
