#!/usr/bin/env python3
"""
Final Model - èåˆ (Fusion) + Submission ç”Ÿæˆè„šæœ¬
--------------------------------------------------------
èåˆä»¥ä¸‹æ£€æµ‹å™¨çš„åˆ†æ•°ï¼š
1ï¸âƒ£ Early_Delinquency_Flag
2ï¸âƒ£ amort_short_mean
3ï¸âƒ£ Zero_Payment_Streak
4ï¸âƒ£ LOF(k=50)

è¾“å‡ºï¼š
- éªŒè¯é›†æ€§èƒ½è¯„ä¼°ï¼ˆfusion_metrics.csvï¼‰
- æµ‹è¯•é›†æäº¤æ–‡ä»¶ï¼ˆsubmission.csvï¼‰
"""

import os
import numpy as np
import pandas as pd
import time
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import average_precision_score, roc_auc_score
from sklearn.neighbors import LocalOutlierFactor

# =========================
# è·¯å¾„å®šä¹‰
# =========================
DATA_PATH = "./data/feature_advanced/"
RESULT_PATH = "./final_models/results/"
SUB_PATH = "./final_models/submission/"
os.makedirs(RESULT_PATH, exist_ok=True)
os.makedirs(SUB_PATH, exist_ok=True)


# =========================
# å·¥å…·å‡½æ•°
# =========================
def safe_load_npy(path: str, fallback_len: int = None):
    """å®‰å…¨åŠ è½½ npy æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é›¶æ•°ç»„"""
    if os.path.exists(path):
        return np.load(path)
    else:
        print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶ç¼ºå¤± {path}ï¼Œä½¿ç”¨é›¶å‘é‡ä»£æ›¿ã€‚")
        return np.zeros(fallback_len)


def load_feature_data():
    """åŠ è½½è®­ç»ƒ/éªŒè¯/æµ‹è¯•ç‰¹å¾ä¸æ ‡ç­¾"""
    X_train = np.load(os.path.join(DATA_PATH, "train_scaled.npy"))
    X_valid = np.load(os.path.join(DATA_PATH, "valid_scaled.npy"))
    X_test = np.load(os.path.join(DATA_PATH, "test_scaled.npy"))
    y_train_full = np.load(os.path.join(DATA_PATH, "train_labels.npy"))
    y_valid = np.load(os.path.join(DATA_PATH, "valid_labels.npy"))
    
    # åŠ è½½ç‰¹å¾åç§°
    feature_names_path = os.path.join(DATA_PATH, "feature_names.txt")
    if os.path.exists(feature_names_path):
        with open(feature_names_path, 'r') as f:
            feature_names = [line.strip() for line in f.readlines() if line.strip()]
    else:
        raise FileNotFoundError(f"æœªæ‰¾åˆ°ç‰¹å¾åç§°æ–‡ä»¶: {feature_names_path}")
    
    normal_mask = (y_train_full == 0)
    X_train_normal = X_train[normal_mask]
    print(f"Train(normal)={X_train_normal.shape}, Valid={X_valid.shape}, Test={X_test.shape}")
    return X_train_normal, X_valid, X_test, y_valid, feature_names


def extract_feature_from_matrix(X_scaled, feature_name, feature_names):
    """ä»ç‰¹å¾çŸ©é˜µä¸­æå–æŒ‡å®šç‰¹å¾"""
    if feature_name not in feature_names:
        raise ValueError(f"ç‰¹å¾ {feature_name} ä¸åœ¨ç‰¹å¾åç§°åˆ—è¡¨ä¸­")
    idx = feature_names.index(feature_name)
    return X_scaled[:, idx]


def run_lof_detector(X_train, X_eval, k=50):
    """è¿è¡Œ LOF æ£€æµ‹å™¨"""
    print(f"è¿è¡Œ LOF(k={k}) æ£€æµ‹å™¨ ...")
    t0 = time.time()
    lof = LocalOutlierFactor(n_neighbors=k, novelty=True, n_jobs=-1)
    lof.fit(X_train)
    scores = -lof.decision_function(X_eval)
    print(f"  -> å®Œæˆ ({time.time() - t0:.2f}s)")
    return scores


# =========================
# ä¸»å‡½æ•°
# =========================
def main():
    print("=" * 70)
    print("Final Model - Fusion Ensemble")
    print("=" * 70)

    # 1ï¸âƒ£ åŠ è½½æ•°æ®
    X_train_normal, X_valid, X_test, y_valid, feature_names = load_feature_data()

    # 2ï¸âƒ£ åŠ è½½ 3 ä¸ªç‰¹å¾æ£€æµ‹å™¨åˆ†æ•°ï¼ˆéªŒè¯é›†ï¼‰
    scores_file = os.path.join(RESULT_PATH, "final_model_scores.csv")
    if not os.path.exists(scores_file):
        raise FileNotFoundError(f"æœªæ‰¾åˆ° {scores_file}ï¼Œè¯·å…ˆè¿è¡Œ generate_ensemble_scores.py")
    scores_df = pd.read_csv(scores_file)
    print(f"åŠ è½½å·²æœ‰æ£€æµ‹å™¨åˆ†æ•°: {list(scores_df.columns)}")

    # 3ï¸âƒ£ è¿è¡Œ LOF(k=50)
    lof_valid = run_lof_detector(X_train_normal, X_valid)
    lof_test = run_lof_detector(X_train_normal, X_test)
    scores_df["LOF_k50"] = lof_valid

    # 4ï¸âƒ£ ä»æµ‹è¯•é›†ä¸­æå–ç‰¹å¾å€¼
    print("\nä»æµ‹è¯•é›†ä¸­æå–ç‰¹å¾å€¼...")
    test_scores = {}
    for col in scores_df.columns:
        if col == "LOF_k50":
            test_scores[col] = lof_test
        else:
            # ä» test_scaled.npy ä¸­æå–ç‰¹å¾
            test_scores[col] = extract_feature_from_matrix(X_test, col, feature_names)
    test_scores_df = pd.DataFrame(test_scores, columns=scores_df.columns)

    # 5ï¸âƒ£ æ ‡å‡†åŒ–
    print("æ ‡å‡†åŒ–åˆ†æ•°åˆ° [0,1] ...")
    scaler = MinMaxScaler()
    # å…ˆåœ¨éªŒè¯é›†ä¸Š fit
    scaled_valid = pd.DataFrame(scaler.fit_transform(scores_df), columns=scores_df.columns)
    # ç„¶ååœ¨æµ‹è¯•é›†ä¸Š transformï¼ˆä½¿ç”¨ç›¸åŒçš„ scalerï¼‰
    scaled_test = pd.DataFrame(scaler.transform(test_scores_df), columns=test_scores_df.columns)

    # 6ï¸âƒ£ èåˆæƒé‡ï¼ˆç»éªŒåŠ æƒï¼‰
    # ç»éªŒå€¼ï¼šå¼ºä¿¡å·æƒé‡å¤§ä¸€äº›
    weights = {
        "Early_Delinquency_Flag": 0.4,
        "amort_short_mean": 0.3,
        "Zero_Payment_Streak": 0.1,
        "LOF_k50": 0.2
    }

    # ç¡®ä¿æ‰€æœ‰æƒé‡å¯¹åº”çš„åˆ—éƒ½å­˜åœ¨
    available_cols = set(scaled_valid.columns)
    weights = {col: w for col, w in weights.items() if col in available_cols}
    # å½’ä¸€åŒ–æƒé‡
    total_weight = sum(weights.values())
    weights = {col: w / total_weight for col, w in weights.items()}
    
    print(f"\nèåˆæƒé‡: {weights}")

    # åŠ æƒèåˆ
    final_valid = sum(w * scaled_valid[col] for col, w in weights.items())
    final_test = sum(w * scaled_test[col] for col, w in weights.items())

    # 7ï¸âƒ£ è¯„ä¼°éªŒè¯é›†æ€§èƒ½
    auprc = average_precision_score(y_valid, final_valid)
    auroc = roc_auc_score(y_valid, final_valid)
    print("\nğŸ“Š Final Fusion Performance:")
    print(f"  AUPRC = {auprc:.6f}")
    print(f"  AUROC = {auroc:.6f}")

    # ä¿å­˜æ€§èƒ½ç»“æœ
    metrics_df = pd.DataFrame({
        "Metric": ["AUPRC", "AUROC"],
        "Value": [auprc, auroc]
    })
    metrics_path = os.path.join(RESULT_PATH, "fusion_metrics.csv")
    metrics_df.to_csv(metrics_path, index=False)
    print(f"âœ… æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°: {metrics_path}")

    # 8ï¸âƒ£ ç”Ÿæˆæäº¤æ–‡ä»¶
    # åŠ è½½æµ‹è¯•é›†ID
    test_ids = np.load(os.path.join(DATA_PATH, "test_ids.npy"))
    
    submission = pd.DataFrame({
        "Id": test_ids.astype(int),
        "target": np.clip(final_test, 0, 1)
    })
    sub_path = os.path.join(SUB_PATH, "submission.csv")
    submission.to_csv(sub_path, index=False)
    print(f"\nâœ… å·²ç”Ÿæˆæäº¤æ–‡ä»¶: {sub_path}")
    print(f"   è¡Œæ•°: {len(submission)}")
    print(f"   åˆ†æ•°èŒƒå›´: [{final_test.min():.6f}, {final_test.max():.6f}]")
    print("\næ–‡ä»¶é¢„è§ˆ:")
    print(submission.head(10))
    
    # ä¿å­˜èåˆæƒé‡æ‘˜è¦
    summary_df = pd.DataFrame([{
        "AUPRC": auprc,
        "AUROC": auroc,
        **{f"Weight_{col}": w for col, w in weights.items()}
    }])
    summary_path = os.path.join(RESULT_PATH, "fusion_summary.csv")
    summary_df.to_csv(summary_path, index=False)
    print(f"\nâœ… èåˆæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_path}")


if __name__ == "__main__":
    main()
